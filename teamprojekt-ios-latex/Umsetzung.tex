\chapter{Bildverarbeitung und Umsetzung}
\label{cha:verarbeitungumsetzung}

Im Groben l"asst sich der Ablauf unseres Programms,
das das Problem der Lokalisierung eines Helikopters im Raum l"ost, folgenderma"sen beschreiben:\newline
Anfangs werden die Kameras separat kalibriert. Ist der berechnete Fehler dieser Kalibrierung gering, werden anschlie"send die Kameras zu einander kalibriert. Wird dann mit beiden Kameras ein Bild der Szene aufgenommen, werden diese Bilder zuerst rektifiziert und anschlie"send entzeichnet. Mit den neuen Bildern ist es m"oglich, eine Tiefenkarte und anschlie"send eine Punktewolke zu generieren. Von dieser Punktwolke wird dann der Mittelpunkt und die Koordinaten dieses Punktes bestimmt. Somit gelangen wir an die $X$-, $Y$- und $Z$-Koordinaten des Helikopters.\newline
Diese Schritte werden im Folgenden detailliert beschrieben.

\section{Kalibrierung}
\label{sec:kalibrierung}

F"ur eine Messung, bei der der Fehler minimiert werden soll, ist das Kalibrieren der Kameras unumg"anglich. Durch die Linse einer Kamera entsteht eine tonnenf"ormige Verzeichnung. Diese Fehler sind meist so klein, dass sie vom menschlichen Auge nicht erfasst werden k"onnen \cite{VZ} \cite{VZ1}. Durch die Kalibrierung der Kamera k"onnen diese kompensiert werden.\newline

\begin{figure}[H]
	\includegraphics[scale=0.45]{bilder/verzeichnung}
	\caption[Verzeichnung]{Verzeichnung}
	\label{fig:verzeichnung}
	\small  uelle: \url{http://www.fotokurs-bremen.de/wp-content/uploads/2016/11/Objektiv-Verzeichnung.jpg}
\end{figure}

\noindent Durch die Kamerakalibrierung werden folgende Parameter bestimmt:

\begin{description}
	\item[Intrinsische Parameter]
	Bezeichnen die Abbildung von 3D-Punkten im Kamerakoordinatensystem auf den 2D-Sensor der Kamera. Es sind Informationen der Kamera selbst, die unabh"angig davon sind, wo sich die Kamera befindet und wie diese ausgerichtet ist \cite{Intr}.
	
	\item[Extrinsische Parameter]
	Die r"aumliche Lage und Orientierung der Kamera zu einem Referenzkoordinatensystem, d.h. die Rotation und Translation \cite{cal} \cite{extr}.
\end{description}

\noindent Da es ich bei dem System um ein Stereokamera-System handelt, ist die Kalibrierung von diesem etwas komplizierter.\newline
Zuerst m"ussen die Kameras gesondert kalibriert werden. Dies wird mit der Funktion \textit{calibrateCamera} von OpenCV durchgef"uhrt. F"ur die Kalibrierung wird ein Schachbrett-Muster verwendet. Wichtig ist, dass bei der Kalibrierung beide Kameras dasselbe Bild verwenden. F"ur die Erkennung des Schachbretts wird die OpenCV-Funktion \textit{findChessboardCorners} verwendet. Diese liefert die Objekt- und Bild-Punkte der Aufnahme. Bei den Objekt-Punkten handelt es sich um die 3D-Punkte des Bildes, bei den Bild-Punkten um die 2D-Punkte \cite{OcvD}.

\begin{figure}[H]
	\includegraphics[scale=0.4]{bilder/calibration}
	\caption[Kalibrierung]{Kalibrierung}
\end{figure}

\noindent F"ur eine m"oglichst genaue Kalibrierung werden 50 Bilder verwendet. Anhand dieser wird jede Kamera mittels \textit{calibrateCamera} kalibriert.\newline
Die Funktion liefert die intrinsisches Parameter in Form von einer \textit{3 x 3} Kamera-Matrix.

\begin{figure}[H]
	\centering
	\includegraphics[scale=0.75]{bilder/matrix}
\end{figure}

\noindent Wobei $f_{x}$ und $f_{y}$ die Brennweite in Pixeln und $c_{x}$ $c_{y}$ ein Hauptpunkt, der normalerweise in der Bildmitte liegt, ist.

\noindent Die Ergebnisse dieses Vorgangs werden auf dem Computer gespeichert, sodass dieser nicht wiederholt werden muss. Anschlie"send wird das Ergebnis der Kalibrierungen an die OpenCV-Funktion \textit{stereoCalibrate} "ubergeben.\newline
Mit Hilfe der Stereo-Kalibrierung kann der Zusammenhang zwischen den Kameras ermittelt werden: Es werden von dem Bezugsbild, welches zum Ursprung des Koordinatensystems wird, die Objekt-Punkte verwendet. Von beiden Kamerasystemen werden die Bild-Punkte, die jeweiligen Kameramatrizen und die Verzeichnungskoeffizienten verwendet. Die f"ur uns wichtigsten Ergebnisse der Stereo-Kalibrierung sind die Rotation und Translation der beiden Kameras zueinander.

\section{Genauigkeitsabsch"atzung der Kalibrierung}
\label{sec:fehlertest}

Der Reprojection Error ist ein qualitatives Ma"s für die Genauigkeit. Der Reprojection Error ist die Distanz zwischen einem detektierten Punkt in dem kalibrierten Bild und dem korrespondierendem Weltpunkt projiziert in dasselbe Bild. Die Reprojection Error Methode ist ein Diagnosewerkzeug um zu erkennen ob eine Verbesserung gemacht werden muss oder nicht. Dies wird in \ref{fig:repro} visuell dargestellt.

\begin{figure}[H]
	\includegraphics[scale=0.75]{bilder/repro_error}
	\caption[Reprojection Error]{Reprojection Error}
	\label{fig:repro}%
	\small Quelle: \url{https://www.researchgate.net/figure/The-reprojection-error-is-the-distance-between-the-projected-image-point-p-and-the_fig3_267557759}
\end{figure}

\section{Stereokalibrierung}
\label{sec:stereokalibrierung}

\begin{figure}%
	\centering
	\subfloat[Stereosystem]{{\includegraphics[width=6cm]{bilder/camerasystem} }}%
	\qquad
	\subfloat[Szenenaufnahme]{{\includegraphics[width=6cm]{bilder/szene} }}%
	\caption{Stereo-System}%
	\small Quelle: \url{https://me.efi.th-nuernberg.de/interaktion/index.php5/Bearbeitung_und_Gewinnung_von_Tiefeninformation_durch_die_Kopplung_zweier_Kameras}
	\label{fig:stereo1}%
\end{figure}

Wie auf dem Bild \ref{fig:stereo1} zu sehen ist, handelt es sich bei unserem Aufbau um ein Stereosystem. Dies ist notwendig f"ur das Berechnen von Tiefeinformationen. Liegen alle Referenzpunkte auf einer geraden, so kann mittels Triangulation, wie auf \ref{fig:baseline} zu sehen ist, der $Z$-Achsen Wert der Punkte berechnet werden.

\begin{figure}[H]
	\includegraphics[scale=1.5]{bilder/baseline}
	\caption[Z-Achsen Berechnung]{Z-Achsen Berechnung}
	\label{fig:baseline}%
	\small Quelle: \url{https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_calib3d/py_depthmap/py_depthmap.html}
\end{figure}

\noindent Da die Kameras horizontal verschoben sind, erhalten wir den Stereonormalfall, der wie folgt beschrieben wird: \textit{Das achsparallele Stereosystem zeichnet sich durch zwei Kameras aus, die nur horizontal verschoben und deren Koordinatensysteme nicht gegeneinander verdreht sind \cite{Tu}.} \newline
\noindent Bei der Stereokalibrierung werden sowohl inneren Kameraparameter f"ur das Stereokamerapaar, als auch die geometrische Lage zwischen den Kameras berechnet \cite{zbs}. OpenCV bietet hierf"ur die Funktion \textit{stereoCalibrate}. Diese Funktion erwartet die vorher berechneten Kameramatrizen und Verzeichnungskoeffizienten beider Kameras. Zudem werden Von beiden Kameras Bildpunkte ben"otigt, die auf die selben Objektpunkte abbilden. Demnach m"ussen beide Kameras auf das selbe Kalibrierobjekt kalibriert werden \cite{ocvs}. Im Programm wird mit beiden Kameras ein Foto der Szene gemacht und anschlie"send versucht, das Schachbrettmuster zu detektieren. War die Detektion bei beiden Bildern erfolgreich, werden die Bild- und Objekt-Punkte gespeichert und der Vorgang 50 mal wiederholt. Nach 50 erfolgreichen Detektierungen werden die Kameras zu einander kalibriert.\newline
Durch die Stereokalibrierung erhalten wir die Rotation und Translation beider Kameras zueinander. Mit diesen Werten ist es m"oglich, Informationen zur Tiefe zu ermitteln. Wie die Werte validiert wurden, wird in \ref{sec:stereovalid} erl"autert.

\subsection{Entzeichnung}
\label{sec:entzeichnung}

Wie in \ref{sec:kalibrierung} erw"ahnt, dient die Kalibrierung die Kompensation der Verzeichnung. Dieser Vorgang wird Entzeichnung genannt. Die Verzeichnung entsteht durch die Bauform der Linse und nimmt mit der Brennweite zu \cite{wie}. Das Entzeichnen eines Bildes erfolgt in OpenCV mittels der Funktion \textit{initUndistortRectifyMap}.

\subsection{Rektifizierung}
\label{sec:rektifizierung}

\noindent Auch wenn es sich bei unserem Aufbau um den Stereonormalfall handelt, existieren dennoch Verschiebungen auf der Y-Achse von Referenzpunkten.

\begin{figure}[H]
	\includegraphics[scale=0.15]{bilder/nonstereo}
	\caption[Stereo Szenenaufnahme]{Stereo Aufnahme}
	\label{fig:steresene}%
\end{figure}

\begin{figure}[H]
	\includegraphics[scale=0.4]{bilder/nonparallal}
	\caption[Stereo Vergr"o"serung]{Stereo Vergr"o"serung}
	\label{fig:vergr}%
\end{figure}

\noindent \ref{fig:steresene} zeigt eine Aufnahme der Kameras. Vergr"o"sert man diese wie in \ref{fig:vergr} sieht man, dass Referenzpunkte nicht immer auf einer Geraden liegen. Dies liegt an der Rotation um die $X$-Achse der beiden Kameras. Diese entsteht zum einen durch das nicht exakte Stativ, zum anderen durch die Montur der Kameras an diesem. Aufgrund dieser Rotation ist es nicht m"oglich Tiefeninformationen der ganzen Szene zu ermitteln. Um dieses Problem zu beheben m"ussen die Bilder rektifiziert werden \cite{zbs}. Mittels der Rektifizierung wird die Rotation beider Kameras berechnet und auf den jeweiligen Aufnahmen kompensiert, sodass Referenzpunkte auf einer geraden Linie liegen. In der Epipolargeometrie wird diese Gerade die Epipolarlinie genannt \cite{ocvs} \cite{wepi}. Nach der Rektifizierung sind alle diese Epipolarlinien parallel. Die Rektifizierung wird in OpenCV mittels der Funktion \textit{stereoRectify} erreicht.

\section{Generierung einer Tiefenkarte} 
\label{sec:gernerierungdep}

Die Tiefenkarte, aus der die Punktewolke generiert wird, wird mit Hilfe des Blockmatching Algorithmus berechnet. Dabei handelt es sich um einen objektorientierter Algorithmus, der zwei gleichgroße Blöcke aus verschiedenen Bildern vergleicht. Es wird ein Bereich im ersten Bild mit allen gleichgroßen Bereichen im zweiten verglichen. Dieser Bereich ist eine \textit{n x m}-Matrix. Der mittlere Quadratische Fehler (MSE) dient als vergleichsmaß, welches sie wie folgt berechnet \cite{HAW}:

\begin{equation}
MSE(x,y,\Delta) = \dfrac{1}{n-m} \sum_{i=-k}^k \sum_{j=-k}^k (|G_{L}(x+i, y+j) - G_{R}(x+i+\Delta, y+j)|^2)
\end{equation}

\noindent $G_{L}$ und $G_{R}$ sind die Bilder als Matrizen in Grauwerten abgespeichert. Der Offset $\Delta$ ist der Indikator f"ur die Sprungweite im zweiten Bild. Nun ist es m"oglich, die Disparit"at $D$ zu bestimmen. Dies beschränkt sich allerdings auf die Bereiche, in der der MSE minimal ist \cite{HAW}:

\begin{equation}
D=\min_{|\Delta|\leq d_{max}} \{MSE(x,y\Delta)\}
\end{equation}

\noindent Durch eine Pixelselektion kann eine Tiefenkarte "uber das ganze Bild erstellt werden.

\begin{figure}%
	\centering
	\subfloat[Stereosystem]{{\includegraphics[width=6cm]{bilder/heli_left} }}%
	\qquad
	\subfloat[Szenenaufnahme]{{\includegraphics[width=6cm]{bilder/heli_right} }}%
	\caption{Aufnahmen eines Helikopters}%
	\label{fig:stereoheli}%
\end{figure}

\noindent \ref{fig:stereoheli} zeigt Aufnahmen des Helikopters von beiden Kameras.

\begin{figure}[H]
	\includegraphics[scale=2.0]{bilder/Tiefenkarte}
	\caption[Tiefenkarte]{Tiefenkarte}
	\label{fig:tiefenkarte}%
\end{figure}

\section{Lokalisierung des Helikopters} 
\label{sec:lokalisierung}

\subsection{k-Means}
\label{subsec:kmeans}

Der k-Means Algorithmus ist eine Clusteranalyse, welche verwendet wird, um einen Clustermittelpunkt zu ermitteln. Dafür ist die Clusteranzahl statisch davor zu bestimmen. Da wir unsere Detektion unter Laborbedingungen durchführen kann davon ausgegangen werden, dass es nur ein Cluster gibt, nämlich die Punktewolke des Helikopters. Demnach wird die Clustergröße auf eins gesetzt, um den Mittelpunkt des Helikopters zu ermitteln. {Der Algorithmus partitioniert die Datenpunkte so, dass die summierte Varianz innerhalb jedes Clusters minimiert wird} \cite{KM}.\newline
\noindent Die Problematik in einem lokalen Minimum hängen zu bleiben entfällt, da es nur ein Cluster gibt. Die euklidische Distanz von jedem Punkt zu dem optimalen clustermittelpunkt wird bestimmt. Der Mittelpunkt des Clusters wird mit folgender Formel berechnet:

\begin{equation}
SSE=\sum_{i=1}^K \sum_{x \in C_i} dist(c_i, x)^{2}
\end{equation}

\noindent SSE (sum of squared error) soll minimiert werden, was zu einem besseren Mittelpunkt des Cluster f"uhrt. Dafür ist es Notwendig $dist$ zu minimieren. Dabei
handelt es sich um den euklidische Abstand von dem Clustermittelpunkt zu dem jeweiligen Punkt. Eine Quadrierung wird vorgenommen um das Vorzeichen zu eliminieren \cite{TUM}. Durch die gegebenen Umstände ist eine Vereinfachung möglich:\newline

\begin{equation}
SSE=\sum_{x \in C_i} dist(c_i, x)^{2} \sum_{i=1}^K
\end{equation}

\noindent Der Anpassungsschritt, in dem der neue Clustermittelpunkt gewählt wird, wird durch das arithmetisches Mittel ausgerechnet:

\begin{equation}
\mu_k = \dfrac{\sum_{n}x_{n}}{n}
\end{equation}

\begin{figure}[H]
	\includegraphics[scale=0.75]{bilder/helicloud}
	\caption[Helikopter Cluster]{Helikopter Cluster}
	\label{fig:helimeans}%
\end{figure}

\noindent In \ref{fig:helimeans} sieht man den angewandten K-Means Algorithmus auf eine generierte Punktewolke aus unserem Kamerasystem. Gut zu erkennen ist, dass der Mittelpunkt des Helikopterclusters auch der tats"achliche Mittelpunkt des Helikopters ist.
